{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Image2SoundFX-jupyter/blob/main/Image2SoundFX_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/haoheliu/audioldm_48k/resolve/main/audioldm_48k.pth -d /content -o audioldm_48k.pth\n",
        "!wget https://huggingface.co/spaces/fffiloni/Image2SFX-comparison/resolve/main/oiseau.png\n",
        "!git clone -b dev https://github.com/camenduru/moondream\n",
        "%cd /content/moondream\n",
        "!pip install -q cog einops moondream timm gradio==3.50.2 diffusers transformers -U\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "import re\n",
        "import gradio as gr\n",
        "from moondream import Moondream, detect_device\n",
        "from threading import Thread\n",
        "from transformers import TextIteratorStreamer, CodeGenTokenizerFast as Tokenizer\n",
        "device, dtype = detect_device()\n",
        "model_id = \"vikhyatk/moondream1\"\n",
        "tokenizer = Tokenizer.from_pretrained(model_id)\n",
        "moondream = Moondream.from_pretrained(model_id).to(device=device, dtype=dtype)\n",
        "moondream.eval()\n",
        "def answer_question(img, prompt):\n",
        "    image_embeds = moondream.encode_image(img)\n",
        "    streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)\n",
        "    thread = Thread(\n",
        "        target=moondream.answer_question,\n",
        "        kwargs={\n",
        "            \"image_embeds\": image_embeds,\n",
        "            \"question\": prompt,\n",
        "            \"tokenizer\": tokenizer,\n",
        "            \"streamer\": streamer,\n",
        "        },\n",
        "    )\n",
        "    thread.start()\n",
        "    buffer = \"\"\n",
        "    for new_text in streamer:\n",
        "        clean_text = re.sub(\"<$|END$\", \"\", new_text)\n",
        "        buffer += clean_text\n",
        "        yield buffer.strip(\"<END\")\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Row():\n",
        "        prompt = gr.Textbox(label=\"Input Prompt\", placeholder=\"Type here...\", scale=4)\n",
        "        submit = gr.Button(\"Submit\")\n",
        "    with gr.Row():\n",
        "        img = gr.Image(type=\"pil\", label=\"Upload an Image\")\n",
        "        output = gr.TextArea(label=\"Response\")\n",
        "    submit.click(answer_question, [img, prompt], output)\n",
        "    prompt.submit(answer_question, [img, prompt], output)\n",
        "demo.queue().launch(debug=False, inline=False, share=True, server_name='0.0.0.0', server_port=1000)\n",
        "\n",
        "%cd /content\n",
        "import gradio as gr\n",
        "import torch\n",
        "from diffusers import AudioLDM2Pipeline\n",
        "device = \"cuda\"\n",
        "torch_dtype = torch.float16\n",
        "repo_id = \"cvssp/audioldm2\"\n",
        "pipe = AudioLDM2Pipeline.from_pretrained(repo_id, torch_dtype=torch_dtype).to(device)\n",
        "generator = torch.Generator(device)\n",
        "def text2audio(text, negative_prompt, duration, guidance_scale, random_seed, n_candidates):\n",
        "    if text is None:\n",
        "        raise gr.Error(\"Please provide a text input.\")\n",
        "    waveforms = pipe(\n",
        "        text,\n",
        "        audio_length_in_s=duration,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=200,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_waveforms_per_prompt=n_candidates if n_candidates else 1,\n",
        "        generator=generator.manual_seed(int(random_seed)),\n",
        "    )[\"audios\"]\n",
        "    return gr.make_waveform((16000, waveforms[0]))\n",
        "iface = gr.Blocks()\n",
        "with iface:\n",
        "    with gr.Group():\n",
        "        textbox = gr.Textbox(\n",
        "            value=\"The vibrant beat of Brazilian samba drums.\",\n",
        "            max_lines=1,\n",
        "            label=\"Input text\",\n",
        "            info=\"Your text is important for the audio quality. Please ensure it is descriptive by using more adjectives.\",\n",
        "            elem_id=\"prompt-in\",\n",
        "        )\n",
        "        negative_textbox = gr.Textbox(\n",
        "            value=\"Low quality.\",\n",
        "            max_lines=1,\n",
        "            label=\"Negative prompt\",\n",
        "            info=\"Enter a negative prompt not to guide the audio generation. Selecting appropriate negative prompts can improve the audio quality significantly.\",\n",
        "            elem_id=\"prompt-in\",\n",
        "        )\n",
        "        with gr.Accordion(\"Click to modify detailed configurations\", open=False):\n",
        "            seed = gr.Number(\n",
        "                value=45,\n",
        "                label=\"Seed\",\n",
        "                info=\"Change this value (any integer number) will lead to a different generation result.\",\n",
        "            )\n",
        "            duration = gr.Slider(5, 15, value=10, step=2.5, label=\"Duration (seconds)\")\n",
        "            guidance_scale = gr.Slider(\n",
        "                0,\n",
        "                7,\n",
        "                value=3.5,\n",
        "                step=0.5,\n",
        "                label=\"Guidance scale\",\n",
        "                info=\"Larger => better quality and relevancy to text; Smaller => better diversity\",\n",
        "            )\n",
        "            n_candidates = gr.Slider(\n",
        "                1,\n",
        "                5,\n",
        "                value=3,\n",
        "                step=1,\n",
        "                label=\"Number waveforms to generate\",\n",
        "                info=\"Automatic quality control. This number control the number of candidates (e.g., generate three audios and choose the best to show you). A larger value usually lead to better quality with heavier computation\",\n",
        "            )\n",
        "        outputs = gr.Video(label=\"Output\", elem_id=\"output-video\")\n",
        "        btn = gr.Button(\"Submit\")\n",
        "    btn.click(\n",
        "        text2audio,\n",
        "        inputs=[textbox, negative_textbox, duration, guidance_scale, seed, n_candidates],\n",
        "        outputs=[outputs],\n",
        "    )\n",
        "iface.queue().launch(debug=False, inline=False, share=True, server_name='0.0.0.0', server_port=2000)\n",
        "\n",
        "import gradio as gr\n",
        "from gradio_client import Client\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from moviepy.editor import VideoFileClip\n",
        "from moviepy.audio.AudioClip import AudioClip\n",
        "def extract_audio(video_in):\n",
        "    input_video = video_in\n",
        "    output_audio = 'audio.wav'\n",
        "    video_clip = VideoFileClip(input_video)\n",
        "    audio_clip = video_clip.audio\n",
        "    audio_clip.write_audiofile(output_audio, fps=44100)\n",
        "    print(\"Audio extraction complete.\")\n",
        "    return 'audio.wav'\n",
        "def get_caption(image_in):\n",
        "    client = Client(\"http://0.0.0.0:1000\")\n",
        "    result = client.predict(\n",
        "        image_in,\n",
        "        \"Describe precisely the image in one sentence.\",\n",
        "        fn_index=0\n",
        "    )\n",
        "    print(result)\n",
        "    return result\n",
        "def get_audioldm(prompt):\n",
        "    client = Client(\"http://0.0.0.0:2000\")\n",
        "    result = client.predict(\n",
        "        prompt,\t# str in 'Input text' Textbox component\n",
        "        \"Low quality. Music.\",\t# str in 'Negative prompt' Textbox component\n",
        "        10,\t# int | float (numeric value between 5 and 15) in 'Duration (seconds)' Slider component\n",
        "        3.5,\t# int | float (numeric value between 0 and 7) in 'Guidance scale' Slider component\n",
        "        45,\t# int | float in 'Seed' Number component\n",
        "        3,\t# int | float (numeric value between 1 and 5) in 'Number waveforms to generate' Slider component\n",
        "        fn_index=1\n",
        "    )\n",
        "    print(result)\n",
        "    audio_result = extract_audio(result)\n",
        "    return audio_result\n",
        "def infer(image_in):\n",
        "    caption = get_caption(image_in)\n",
        "    audioldm_result = get_audioldm(caption)\n",
        "    return audioldm_result\n",
        "css=\"\"\"\n",
        "#col-container{\n",
        "    margin: 0 auto;\n",
        "    max-width: 800px;\n",
        "}\n",
        "\"\"\"\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    with gr.Column(elem_id=\"col-container\"):        \n",
        "        with gr.Column():\n",
        "            image_in = gr.Image(sources=[\"upload\"], type=\"filepath\", label=\"Image input\", value=\"oiseau.png\")\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"Submit\")\n",
        "        with gr.Column():\n",
        "            audio_o = gr.Audio(label=\"Audio output\")\n",
        "    submit_btn.click(\n",
        "        fn=infer,\n",
        "        inputs=[image_in],\n",
        "        outputs=[audio_o],\n",
        "    )\n",
        "demo.queue().launch(debug=True, show_error=True, share=True, inline=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
